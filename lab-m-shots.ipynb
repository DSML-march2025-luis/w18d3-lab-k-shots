{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b19fff-8f42-4e9f-a73e-00cff106805a",
   "metadata": {},
   "source": [
    "# M-Shots Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34723a72-1601-4685-a0ba-bff544425d48",
   "metadata": {
    "id": "34723a72-1601-4685-a0ba-bff544425d48"
   },
   "source": [
    "In this notebook, we'll explore small prompt engineering techniques and recommendations that will help us elicit responses from the models that are better suited to our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba193cc-d8a0-4ad2-8177-380204426859",
   "metadata": {
    "id": "fba193cc-d8a0-4ad2-8177-380204426859"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502cfc93-21e0-498f-9650-37bc6ddd514d",
   "metadata": {
    "id": "502cfc93-21e0-498f-9650-37bc6ddd514d"
   },
   "source": [
    "# Formatting the answer with Few Shot Samples.\n",
    "\n",
    "To obtain the model's response in a specific format, we have various options, but one of the most convenient is to use Few-Shot Samples. This involves presenting the model with pairs of user queries and example responses.\n",
    "\n",
    "Large models like GPT-3.5 respond well to the examples provided, adapting their response to the specified format.\n",
    "\n",
    "Depending on the number of examples given, this technique can be referred to as:\n",
    "* Zero-Shot.\n",
    "* One-Shot.\n",
    "* Few-Shots.\n",
    "\n",
    "With One Shot should be enough, and it is recommended to use a maximum of six shots. It's important to remember that this information is passed in each query and occupies space in the input prompt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8344712-06d7-4c24-83d8-f36d62926e5e",
   "metadata": {
    "id": "a8344712-06d7-4c24-83d8-f36d62926e5e"
   },
   "outputs": [],
   "source": [
    "# Function to call the model.\n",
    "def return_OAIResponse(user_message, context):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=1,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f611d73d-9330-466d-b705-543667e1b561",
   "metadata": {
    "id": "f611d73d-9330-466d-b705-543667e1b561"
   },
   "source": [
    "In this zero-shots prompt we obtain a correct response, but without formatting, as the model incorporates the information he wants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "647790be-fdb8-4692-a82e-7e3a0220f72a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "647790be-fdb8-4692-a82e-7e3a0220f72a",
    "outputId": "4c4a9f4f-67c9-4a11-837f-1a1fd6b516ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael Schumacher won the F1 World Championship in 2000 driving for Scuderia Ferrari.\n"
     ]
    }
   ],
   "source": [
    "#zero-shot\n",
    "context_user = [\n",
    "    {'role':'system', 'content':'You are an expert in F1.'}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2000?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a9a0a-c1b9-4759-b52f-f6547d29b4c8",
   "metadata": {
    "id": "e87a9a0a-c1b9-4759-b52f-f6547d29b4c8"
   },
   "source": [
    "For a model as large and good as GPT 3.5, a single shot is enough to learn the output format we expect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ac7693-6cf3-44f7-b2ff-55d8a36fe775",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33ac7693-6cf3-44f7-b2ff-55d8a36fe775",
    "outputId": "5278df23-8797-4dc2-9340-ac29c1318a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: Sebastian Vettel.\n",
      "Team: Red Bull Racing.\n"
     ]
    }
   ],
   "source": [
    "#one-shot\n",
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in F1.\n",
    "\n",
    "     Who won the 2000 f1 championship?\n",
    "     Driver: Michael Schumacher.\n",
    "     Team: Ferrari.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2011?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c454a8-181b-482b-873a-81d6ffde4674",
   "metadata": {
    "id": "32c454a8-181b-482b-873a-81d6ffde4674"
   },
   "source": [
    "Smaller models, or more complicated formats, may require more than one shot. Here a sample with two shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce600f7-f92e-4cf7-be4a-408f12eb39d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ce600f7-f92e-4cf7-be4a-408f12eb39d6",
    "outputId": "a6f90f5d-6d68-4b3d-ccb5-5848ae4e3e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: Fernando Alonso.\n",
      "Team: Renault.\n"
     ]
    }
   ],
   "source": [
    "#Few shots\n",
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in F1.\n",
    "\n",
    "     Who won the 2010 f1 championship?\n",
    "     Driver: Sebastian Vettel.\n",
    "     Team: Red Bull Renault.\n",
    "\n",
    "     Who won the 2009 f1 championship?\n",
    "     Driver: Jenson Button.\n",
    "     Team: BrawnGP.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b29898a-f715-46d4-b74b-9f95d3112d38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b29898a-f715-46d4-b74b-9f95d3112d38",
    "outputId": "75f63fe3-0efc-45ed-dd45-71dbbb08d7a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: Lewis Hamilton. \n",
      "Team: Mercedes.\n"
     ]
    }
   ],
   "source": [
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b71c4-6583-4dcb-b987-02abf6aa4a86",
   "metadata": {
    "id": "5f1b71c4-6583-4dcb-b987-02abf6aa4a86"
   },
   "source": [
    "We've been creating the prompt without using OpenAI's roles, and as we've seen, it worked correctly.\n",
    "\n",
    "However, the proper way to do this is by using these roles to construct the prompt, making the model's learning process even more effective.\n",
    "\n",
    "By not feeding it the entire prompt as if they were system commands, we enable the model to learn from a conversation, which is more realistic for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20fa4a25-01a6-4f22-98db-ab7ccc9ba115",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20fa4a25-01a6-4f22-98db-ab7ccc9ba115",
    "outputId": "868d2040-ca3c-4a47-a1e8-1e08d581191d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: Lewis Hamilton. \n",
      "Team: Mercedes. \n",
      "Points: 413.\n"
     ]
    }
   ],
   "source": [
    "#Recomended solution\n",
    "context_user = [\n",
    "    {'role':'system', 'content':'You are and expert in f1.\\n\\n'},\n",
    "    {'role':'user', 'content':'Who won the 2010 f1 championship?'},\n",
    "    {'role':'assistant', 'content':\"\"\"Driver: Sebastian Vettel. \\nTeam: Red Bull. \\nPoints: 256. \"\"\"},\n",
    "    {'role':'user', 'content':'Who won the 2009 f1 championship?'},\n",
    "    {'role':'assistant', 'content':\"\"\"Driver: Jenson Button. \\nTeam: BrawnGP. \\nPoints: 95. \"\"\"},\n",
    "]\n",
    "\n",
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f6b42-f351-496b-a7e8-1286426457eb",
   "metadata": {
    "id": "ac6f6b42-f351-496b-a7e8-1286426457eb"
   },
   "source": [
    "We could also address it by using a more conventional prompt, describing what we want and how we want the format.\n",
    "\n",
    "However, it's essential to understand that in this case, the model is following instructions, whereas in the case of use shots, it is learning in real-time during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36c32a32-c348-45b2-85ee-ab4500438c49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36c32a32-c348-45b2-85ee-ab4500438c49",
    "outputId": "4c970dde-37ff-41a9-8d4e-37bb727f47a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: Lewis Hamilton\n",
      "Team: Mercedes\n",
      "Points: 413\n"
     ]
    }
   ],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\"\"\"You are and expert in f1.\n",
    "    You are going to answer the question of the user giving the name of the rider,\n",
    "    the name of the team and the points of the champion, following the format:\n",
    "    Drive:\n",
    "    Team:\n",
    "    Points: \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "KNDL1GzVngyL",
   "metadata": {
    "id": "KNDL1GzVngyL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: Fernando Alonso.\n",
      "Team: Renault.\n"
     ]
    }
   ],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are classifying .\n",
    "\n",
    "     Who won the 2010 f1 championship?\n",
    "     Driver: Sebastian Vettel.\n",
    "     Team: Red Bull Renault.\n",
    "\n",
    "     Who won the 2009 f1 championship?\n",
    "     Driver: Jenson Button.\n",
    "     Team: BrawnGP.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qZPNTLMPnkQ4",
   "metadata": {
    "id": "qZPNTLMPnkQ4"
   },
   "source": [
    "Few Shots for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ejcstgTxnnX5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejcstgTxnnX5",
    "outputId": "4b91cc73-18f6-4944-a46b-806b02b7becb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in reviewing product opinions and classifying them as positive or negative.\n",
    "\n",
    "     It fulfilled its function perfectly, I think the price is fair, I would buy it again.\n",
    "     Sentiment: Positive\n",
    "\n",
    "     It didn't work bad, but I wouldn't buy it again, maybe it's a bit expensive for what it does.\n",
    "     Sentiment: Negative.\n",
    "\n",
    "     I wouldn't know what to say, my son uses it, but he doesn't love it.\n",
    "     Sentiment: Neutral\n",
    "     \"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"I'm not going to return it, but I don't plan to buy it again.\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe1d50b-d262-4e74-8f2d-3559f3fcfb15",
   "metadata": {
    "id": "ZHr_75sDqDJp"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
    " - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d503da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendRequestLLM(user_message, context):\n",
    "    client = OpenAI()\n",
    "\n",
    "    new_context = context.copy()\n",
    "    new_context.append({\"role\": \"user\", \"content\": user_message })\n",
    "\n",
    "    res = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=new_context,\n",
    "        temperature=0.1, # Lower temperature for more deterministic responses\n",
    "        max_tokens=150, # Limit the response length\n",
    "    )\n",
    "\n",
    "    return res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6448a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = [\n",
    "    {\"role\": \"system\", \"content\": \"You're an expert in Master Chef Spain. If you are asked for the winner in a given edition, anwer with the name of the winner. If you don't know the answer, respond with 'Sorry, no data available.'\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won 'MasterChef España (formato aficionados)' in 2013?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Juan Manuel Sánchez.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won 'MasterChef España (formato aficionados)' in 2014?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Vicky Pulgarín.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won 'MasterChef España (formato aficionados)' in 2015?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Carlos Maldonado.\"},\n",
    "    # editions in the coming future\n",
    "    {\"role\": \"user\", \"content\": \"Who won 'MasterChef España (formato aficionados)' in 2030?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sorry, no data available.\"},\n",
    "    # editions in the past, before the first edition even took place\n",
    "    {\"role\": \"user\", \"content\": \"Who won 'MasterChef España (formato aficionados)' in 2005?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sorry, no data available.\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "963866c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Juan Manuel Sánchez.\n"
     ]
    }
   ],
   "source": [
    "answer = sendRequestLLM(\"Who won 'MasterChef España (formato aficionados)' in 2013?\", ctx)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9e364b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vicky Pulgarín.\n"
     ]
    }
   ],
   "source": [
    "answer = sendRequestLLM(\"Who won 'MasterChef España (formato aficionados)' in 2014?\", ctx)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c042a5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virginia.\n"
     ]
    }
   ],
   "source": [
    "answer = sendRequestLLM(\"Who won 'MasterChef España (formato aficionados)' in 2016?\", ctx)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "678535f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ana Iglesias.\n"
     ]
    }
   ],
   "source": [
    "answer = sendRequestLLM(\"Who won 'MasterChef España (formato aficionados)' in 2020?\", ctx)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3cae260f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, no data available.\n"
     ]
    }
   ],
   "source": [
    "answer = sendRequestLLM(\"Who won 'MasterChef España (formato aficionados)' in 1992?\", ctx)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cf275ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, no data available.\n"
     ]
    }
   ],
   "source": [
    "answer = sendRequestLLM(\"Who won 'MasterChef España (formato aficionados)' in 2024?\", ctx)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26e3266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ana Iglesias.\n",
      "Sorry, no data available.\n",
      "The winners of MasterChef España (formato aficionados) come from different regions of Spain.\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# follow up on previous questions\n",
    "# \n",
    "\n",
    "answer = sendRequestLLM(\"Who won 'MasterChef España (formato aficionados)' in 2020?\", ctx)\n",
    "print(answer)\n",
    "\n",
    "\n",
    "answer = sendRequestLLM(\"Where is she from?\", ctx)\n",
    "print(answer) # asking a follow-up question about the previous answer, will not work as expected because the model does not remember previous interactions (unless you provide the context again)\n",
    "\n",
    "\n",
    "answer = sendRequestLLM(\"Where is the person that won 'MasterChef España (formato aficionados)' from?\", ctx)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dbf8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Los Angeles Lakers won the NBA championship in 2020.\n",
      "The Milwaukee Bucks won the NBA championship in 2021.\n",
      "I am sorry, but I am unable to provide real-time information as I do not have access to the internet. Please check the latest news or sports websites for the most up-to-date information on the winner of the NBA in 2022.\n",
      "I'm sorry, but I am unable to provide real-time information as I am an AI assistant and do not have access to current data. Please check the latest news or sports websites for the most up-to-date information on the winner of the NBA in 2024.\n",
      "I'm sorry, but as an AI, I do not have access to real-time information. I recommend checking the latest sports news or the official NBA website to find out who won the NBA in 2042.\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# asking specifically for info after the training cutoff date\n",
    "# (GPT-3.5 Turbo model's knowledge cutoff date is September 2021)\n",
    "# \n",
    "\n",
    "answer = sendRequestLLM(\"Who won the NBA in 2020?\", [])\n",
    "print(answer) # Los Angeles Lakers --> correct\n",
    "\n",
    "answer = sendRequestLLM(\"Who won the NBA in 2021?\", [])\n",
    "print(answer) # Milwaukee Bucks --> correct\n",
    "\n",
    "answer = sendRequestLLM(\"Who won the NBA in 2022?\", [])\n",
    "print(answer) # \"I am unable to provide real-time information\" --> good, at least the model is not hallucinating an answer\n",
    "\n",
    "answer = sendRequestLLM(\"Who won the NBA in 2024?\", [])\n",
    "print(answer) # good as well. To get the same format, we could do few-shot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69364483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los Angeles Lakers.\n",
      "Milwaukee Bucks.\n",
      "Milwaukee Bucks.\n",
      "Sorry, no data available.\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# asking specifically for info after the training cutoff date (second iteration)\n",
    "# \n",
    "\n",
    "\n",
    "ctx = [\n",
    "    {\"role\": \"system\", \"content\": \"You're an expert in Basketball and the NBA. If you're asked for the winner of the NBA, answer only with the name of the winning team. If you can not find the answer, respond with 'Sorry, no data available.'\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the NBA in 1993?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Chicago Bulls.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the NBA in 1994?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Houston Rockets.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the NBA in 2042?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sorry, no data available.\"},\n",
    "]\n",
    "\n",
    "\n",
    "answer = sendRequestLLM(\"Who won the NBA in 2020?\", ctx)\n",
    "print(answer) \n",
    "\n",
    "answer = sendRequestLLM(\"Who won the NBA in 2021?\", ctx)\n",
    "print(answer)\n",
    "\n",
    "answer = sendRequestLLM(\"Who won the NBA in 2022?\", ctx)\n",
    "print(answer) \n",
    "\n",
    "answer = sendRequestLLM(\"Who won the NBA in 2024?\", ctx)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ecb7ea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but as an AI, I do not have real-time information. Please check the latest news or sports websites for the most up-to-date information on the winner of the NBA in 2024.\n",
      "I'm sorry, but as an AI, I do not have the capability to browse the internet in real-time. However, you can easily find the answer by searching for \"NBA champion 2024\" on a search engine or checking the official NBA website for the most recent information.\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# beggin for web search\n",
    "# \n",
    "\n",
    "\n",
    "answer = sendRequestLLM(\"Who won the NBA in 2024?\", [])\n",
    "print(answer) \n",
    "\n",
    "answer = sendRequestLLM(\"I really really need to know who won the NBA in 2024. Can you please do some research, find the answer and tell me who won?\", [])\n",
    "print(answer) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8634352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Key findings:\n",
    "#\n",
    "#\n",
    "# 1. For accurate results and deterministic responses, using a low temperature is essential. This reduces randomness in the model's responses, making it more reliable for factual queries. In the examples above, where we need factual information, using a temperature of 1 was giving unpredictable results.\n",
    "#\n",
    "#\n",
    "# 2. When dealing with LLM apis, it is important to iterate and refine, as the first attempt may not yield the desired results. In addition to that, it is important to cover the edge cases, as the model may not be able to answer questions about them.\n",
    "#\n",
    "#\n",
    "# 3. OpenAI API is stateless and does not remember previous interactions. It is important to provide context for each request, as they do not retain memory of previous interactions.\n",
    "#\n",
    "#\n",
    "# 4. As of today, most LLM APIs do not support web browsing or real-time data retrieval, so responses are based on the training data available up to a certain date. It's up to the developer to implement web search by combining the LLM API with a web search API.\n",
    "#    - Note: Perplexity seems to be offering that for Sonar Pro API and I think it's reasonable to expect that from most LLM APIs in the upcoming future (since they're already offering this on their user interface versions).\n",
    "#    - More info: https://chatgpt.com/share/687e668d-724c-8003-b3bd-81c6ccef9924\n",
    "#    - Sonar Pro API: https://www.perplexity.ai/hub/blog/introducing-the-sonar-pro-api\n",
    "#\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
